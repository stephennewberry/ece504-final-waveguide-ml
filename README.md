# Machine Learning for Detection of Modal Configurations in Rectangular Waveguides
### Author: Stephen Newberry
### Date: 09-MAY-2022

This code was written for a class project in the course entitled ECE 504: "Machine Learning for Electromagnetics" that was taught in Spring 2022 by Prof. Zadehgol at the University of Idaho in Moscow, Idaho.

# Overview
This project creates multiple machine learning models which can be used to determine modal characteristics within a rectangular waveguide based on magnitude and phase of the field data. The models are trained with waveguides of varying dimension as detailed in the included report.

# Licensing
This project, repo, and all associated files are governed by the GNU GPLv3 license as indicated within the included LICENSE file.

# Files
This repo is arranged into two separate subdirectories:
* Code
  + Contains all code, test/traning data, pickle files, and saved Keras models required to run the project code
* Report
  + Contains all files relevant to the report including LaTeX source, images, and output PDF
* Results
  + This directory does not contain any pertinent information for the report. Since the primary method of programming is with a Jupyter notebook, the code and documentation is created together.

There is also a `.idea` directory if the user has a JetBrains IDE. 

# Code
This project is designed as a Jupyter notebook which can be run standalone. All requirements must be installed (see **Python Version Info** section below).

Note that the Git repository contains some very large files which require separate download. Unfortunately, they exceed the free storage limits of Github. They may be generated by running the code (which will take quite a long time) or they can be downloaded from the following link:
https://vandalsuidaho-my.sharepoint.com/:f:/g/personal/newb8262_vandals_uidaho_edu/EjuWJDmwRe5OmsUs9vSkMUMBY7XDytSgHppzNPhus_Y69Q?e=ggNHDH

The specific files included here are:
* training_data_compressed.pkl
  + Place in `Code` directory
* test_data_compressed.pkl
  + Place in `Code` directory
* keras_model.7z
  + Unzip and place directory within `Code` directory
* keras_model_gaussian.7z
  + Unzip and place directory within `Code` directory

# Run Instructions
Simply open and run the `Project_4_Newberry_Final.ipynb` Jupyter notebook. Note that there are a few paramters in-line which modify behavior:
* generate_training_set
  + Set to `True` to generate new training data
  + If the existing training data has been saved as a `pkl` file, it may be used instead by setting this to `False`
* generate_test_set
  + Set to `True` to generate new test data
  + If the existing test data has been saved as a `pkl` file, it may be used instead by setting this to `False`
* reprep_data
  + This function formats the test and training data with a `True` setting
  + The operation is relatively slow, so to save time on subsequent runs if there is no change to the variables the cell may easily be skipped with this variable
* train_model
  + Set to `True` to fit the neural net model
  + Due to the time required for training, it can be set to `False` if the keras model directory already exists
* train_new_models
  + Set to `True` to fit the decision tree model
  + Set to `False` if the decision tree models have been created already

# Input Parameters
No specific input paramters are required for the program to run. Note that the `p4_functions.py` must be in the same directory.

# Output Parameters
There are no program outputs from the Jupyter notebook.

# Usage
Simpy open the notebook and run. Note the Run Instructions listed above.

# Python Version Info
The project uses Python version 3.7.9, specifically within the JetBrains DataSpell IDE. 

## Requirements
See the included `requirements.txt` file, or the list below. 

<details>
  <summary>Click to expand:</summary>
  
* absl-py==0.12.0
* anyio==3.5.0
* apache-beam==2.35.0
* appdirs==1.4.4
* argon2-cffi==21.3.0
* argon2-cffi-bindings==21.2.0
* astunparse==1.6.3
* attrs==20.3.0
* AutoROM==0.4.2
* AutoROM.accept-rom-license==0.4.2
* backcall==0.2.0
* bleach==4.1.0
* cached-property==1.5.2
* cachetools==4.2.4
* certifi==2021.10.8
* cffi==1.15.0
* charset-normalizer==2.0.10
* clang==5.0
* click==7.1.2
* cloudpickle==2.0.0
* colorama==0.4.4
* crcmod==1.7
* cycler==0.11.0
* debugpy==1.5.1
* decorator==5.1.1
* defusedxml==0.7.1
* dill==0.3.1.1
* dm-tree==0.1.6
* docker==4.4.4
* docopt==0.6.2
* entrypoints==0.3
* fastavro==1.4.9
* fasteners==0.16.3
* filelock==3.4.2
* flatbuffers==1.12
* ftfy==6.0.3
* future==0.18.2
* gast==0.4.0
* gin-config==0.5.0
* gitdb==4.0.9
* GitPython==3.1.26
* google-api-core==1.31.5
* google-api-python-client==1.12.10
* google-apitools==0.5.31
* google-auth==1.35.0
* google-auth-httplib2==0.1.0
* google-auth-oauthlib==0.4.6
* google-cloud-aiplatform==1.9.0
* google-cloud-bigquery==2.32.0
* google-cloud-bigquery-storage==2.11.0
* google-cloud-bigtable==1.7.0
* google-cloud-core==1.7.2
* google-cloud-datastore==1.15.3
* google-cloud-dlp==3.4.0
* google-cloud-language==1.3.0
* google-cloud-pubsub==1.7.0
* google-cloud-recommendations-ai==0.2.0
* google-cloud-spanner==1.19.1
* google-cloud-storage==1.44.0
* google-cloud-videointelligence==1.16.1
* google-cloud-vision==1.0.0
* google-crc32c==1.3.0
* google-pasta==0.2.0
* google-resumable-media==2.1.0
* googleapis-common-protos==1.54.0
* graphviz==0.19.1
* grpc-google-iam-v1==0.12.3
* grpcio==1.43.0
* grpcio-gcp==0.2.2
* gviz-api==1.10.0
* gym==0.21.0
* h5py==3.1.0
* hdfs==2.6.0
* httplib2==0.19.1
* huggingface-hub==0.4.0
* idna==3.3
* importlib-metadata==4.10.0
* importlib-resources==5.4.0
* ipykernel==6.7.0
* ipython==7.31.0
* ipython-genutils==0.2.0
* ipywidgets==7.6.5
* jedi==0.18.1
* Jinja2==3.0.3
* joblib==0.14.1
* jsonschema==4.4.0
* jupyter==1.0.0
* jupyter-client==7.1.0
* jupyter-console==6.4.0
* jupyter-core==4.9.1
* jupyter-server==1.13.2
* jupyter-server-mathjax==0.2.3
* jupyterlab-pygments==0.1.2
* jupyterlab-widgets==1.0.2
* keras==2.6.0
* Keras-Preprocessing==1.1.2
* keras-tuner==1.1.0
* kiwisolver==1.3.2
* kt-legacy==1.0.4
* kubernetes==12.0.1
* libcst==0.4.0
* Markdown==3.3.6
* MarkupSafe==2.0.1
* matplotlib==3.4.3
* matplotlib-inline==0.1.3
* mistune==0.8.4
* ml-metadata==1.3.0
* ml-pipelines-sdk==1.3.4
* mypy-extensions==0.4.3
* nbclient==0.5.10
* nbconvert==6.4.0
* nbdime==3.1.1
* nbformat==5.1.3
* nest-asyncio==1.5.4
* nltk==3.6.7
* notebook==6.4.7
* numexpr==2.7.3
* numpy==1.19.5
* oauth2client==4.1.3
* oauthlib==3.1.1
* opencv-python==4.5.3.56
* opt-einsum==3.3.0
* orjson==3.6.5
* packaging==20.9
* pandas==1.3.5
* pandocfilters==1.5.0
* parso==0.8.3
* pickleshare==0.7.5
* Pillow==8.4.0
* portpicker==1.5.0
* prometheus-client==0.12.0
* promise==2.3
* prompt-toolkit==3.0.24
* proto-plus==1.19.8
* protobuf==3.19.3
* psutil==5.9.0
* pyarrow==2.0.0
* pyasn1==0.4.8
* pyasn1-modules==0.2.8
* pycparser==2.21
* pydot==1.4.2
* pyglet==1.5.21
* Pygments==2.11.2
* pymongo==3.12.3
* pyparsing==2.4.7
* pyrsistent==0.18.0
* python-dateutil==2.8.2
* pytz==2021.3
* pywin32==227
* pywinpty==1.1.6
* PyYAML==5.4.1
* pyzmq==22.3.0
* qtconsole==5.2.2
* QtPy==2.0.0
* regex==2021.11.10
* requests==2.26.0
* requests-oauthlib==1.3.0
* rsa==4.8
* sacremoses==0.0.47
* scikit-learn==1.0.2
* scipy==1.7.3
* Send2Trash==1.8.0
* siunits==0.0.6
* six==1.15.0
* smmap==5.0.0
* sniffio==1.2.0
* tensorboard==2.7.0
* tensorboard-data-server==0.6.1
* tensorboard-plugin-profile==2.5.0
* tensorboard-plugin-wit==1.8.1
* tensorflow==2.6.2
* tensorflow-addons==0.14.0
* tensorflow-data-validation==1.3.0
* tensorflow-datasets==4.4.0
* tensorflow-estimator==2.6.0
* tensorflow-hub==0.12.0
* tensorflow-metadata==1.2.0
* tensorflow-model-analysis==0.34.1
* tensorflow-probability==0.14.1
* tensorflow-serving-api==2.6.2
* tensorflow-transform==1.3.0
* termcolor==1.1.0
* terminado==0.12.1
* testpath==0.5.0
* tf-agents==0.10.0
* tfx==1.3.4
* tfx-bsl==1.3.0
* threadpoolctl==3.0.0
* tokenizers==0.10.3
* tornado==6.1
* tqdm==4.62.3
* traitlets==5.1.1
* transformers==4.11.3
* typeguard==2.13.3
* typing-extensions==3.7.4.3
* typing-inspect==0.7.1
* uritemplate==3.0.1
* uritools==4.0.0
* urlextract==1.4.0
* urllib3==1.26.8
* wcwidth==0.2.5
* webencodings==0.5.1
* websocket-client==1.2.3
* Werkzeug==2.0.2
* widgetsnbextension==3.5.2
* wrapt==1.12.1
* xgboost==1.4.2
* zipp==3.7.0
</details>

# References
[1]D. M. Pozar, Microwave engineering, 4th ed. Hoboken, NJ: Wiley, 2012.

[2]“Adam.” https://keras.io/api/optimizers/adam/ (accessed Dec. 28, 2021).

[3]“Keras: the Python deep learning API.” https://keras.io/ (accessed Dec. 28, 2021).

[4]K. Team, “Keras documentation: Losses.” https://keras.io/api/losses/ (accessed Jan. 09, 2022).

[5]“Root-mean-square deviation,” Wikipedia. Aug. 06, 2021. Accessed: Jan. 13, 2022. [Online]. Available: https://en.wikipedia.org/wiki/RMSD

[6]A. Géron, Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow: concepts, tools, and techniques to build intelligent systems, Second edition. Beijing [China] ; Sebastopol, CA: O’Reilly Media, Inc, 2019.

[7]A. Zadehgol, “ECE 504, University of Idaho,” Moscow, ID, Spring 2022.

[8]F. Pedregosa et al., “Scikit-learn: Machine Learning in Python,” Journal of Machine Learning Research, vol. 12, pp. 2825–2830, 2011.

[9]“Cross-validation (statistics),” Wikipedia. Jan. 09, 2022. Accessed: Feb. 07, 2022. [Online]. Available: https://en.wikipedia.org/wiki/Cross-validation_(statistics)

[10]“MNIST database,” Wikipedia. Feb. 10, 2022. Accessed: Feb. 10, 2022. [Online]. Available: https://en.wikipedia.org/w/index.php?title=MNIST_database&oldid=1071024311

[11]J. Smith, “The U.S. Cities Where People Earn The Biggest And Smallest Paychecks,” Forbes. https://www.forbes.com/sites/jacquelynsmith/2013/11/27/the-u-s-cities-where-people-earn-the-biggest-and-smallest-paychecks/ (accessed Feb. 10, 2022).

[12]“sklearn.ensemble.GradientBoostingRegressor,” scikit-learn. https://scikit-learn/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html (accessed Feb. 10, 2022).

[13]“sklearn.ensemble.HistGradientBoostingRegressor,” scikit-learn. https://scikit-learn/stable/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html (accessed Feb. 10, 2022).

[14]“sklearn.linear_model.LinearRegression,” scikit-learn. https://scikit-learn/stable/modules/generated/sklearn.linear_model.LinearRegression.html (accessed Feb. 10, 2022).

[15]“sklearn.linear_model.SGDClassifier,” scikit-learn. https://scikit-learn/stable/modules/generated/sklearn.linear_model.SGDClassifier.html (accessed Feb. 10, 2022).

[16]“sklearn.svm.SVC,” scikit-learn. https://scikit-learn/stable/modules/generated/sklearn.svm.SVC.html (accessed Feb. 10, 2022).

[17]R. Kumar et al., “Knowledge-Based Neural Networks for Fast Design Space Exploration of Hybrid Copper-Graphene On-Chip Interconnect Networks,” IEEE Transactions on Electromagnetic Compatibility, vol. 64, no. 1, pp. 182–195, Feb. 2022, doi: 10.1109/TEMC.2021.3091714.

[18]T. pandas development team, pandas-dev/pandas: Pandas. Zenodo, 2020. doi: 10.5281/zenodo.3509134.

[19]“Artificial neural network,” Wikipedia. Mar. 05, 2022. Accessed: Mar. 10, 2022. [Online]. Available: https://en.wikipedia.org/w/index.php?title=Artificial_neural_network&oldid=1075364983

[20]“Rectifier (neural networks),” Wikipedia. Feb. 27, 2022. Accessed: Mar. 10, 2022. [Online]. Available: https://en.wikipedia.org/w/index.php?title=Rectifier_(neural_networks)&oldid=1074306665

[21]S. Newberry, “Machine Learning for Electromagnetics: Project 2,” University of Idaho, Mar. 2022.

[22]“pickle — Python object serialization — Python 3.10.4 documentation.” https://docs.python.org/3/library/pickle.html (accessed Apr. 09, 2022).

[23]“Random sampling (numpy.random) — NumPy v1.22 Manual.” https://numpy.org/doc/stable/reference/random/ (accessed Apr. 09, 2022).

[24]“1.10. Decision Trees,” scikit-learn. https://scikit-learn/stable/modules/tree.html (accessed Apr. 11, 2022).

[25]“1.4. Support Vector Machines,” scikit-learn. https://scikit-learn/stable/modules/svm.html (accessed Apr. 12, 2022).

[26]S. Newberry, “Machine Learning for Electromagnetics: Project 3,” University of Idaho, Apr. 2022.

[27]“Exponential distribution,” Wikipedia. Apr. 15, 2022. Accessed: May 07, 2022. [Online]. Available: https://en.wikipedia.org/w/index.php?title=Exponential_distribution&oldid=1082827254

[28]“numpy.random.exponential — NumPy v1.22 Manual.” https://numpy.org/doc/stable/reference/random/generated/numpy.random.exponential.html (accessed May 07, 2022).

[29]R. D. Yates and D. J. Goodman, Probability and stochastic processes: a friendly introduction for electrical and computer engineers, Third edition. Hoboken, NJ: John Wiley & Sons, 2014.
